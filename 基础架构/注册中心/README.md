# 注册中心

常见开源软件

> Nacos、ZooKeeper、Apollo、Dubbo

## 作用（使用者）

注册中心，用来实现微服务实例的自动注册与发现，是分布式系统中的核心基础服务。

### 无注册中心场景

![无注册中心场景](Zookeeper\imgs\无注册中心场景.png)

* 模块各自维护

  **在上游模块进行配置，指定要调用的下游模块的信息。**

  如果流量稳定，不需要改配置，问题不大。问题是电商经常搞运营活动，流量波动大，需要频繁地扩容缩容，频繁改配置，这就增加了极大的沟通成本。

  比如，甲乙丙丁分别负责ABCD四个模块，ABC都要调用D。甲乙丙分别在ABC模块上配置D模块路由信息。现在运营搞活动，甲乙丙各自预估流量，分别通知丁：“我需要多少流量”，丁收到通知，预估流量，发现需要加机器扩容D服务。然后丁申请资源进行扩容。丁完成扩容后，将新路由信息发到群里，甲乙丙各自更新配置。到这一步没有任何问题。活动结束后，流量小了，不能白白占用这么多资源，丁要下线部分D服务，释放多余的资源。但问题是丁不清楚具体都有谁调用了D服务，只能在群里喊话。下线部分B服务这个事情，经常两个星期解决不了。

* 全局配置文件

  所有服务使用全局配置文件，由运维维护。跨部门协作很难。**使用技术手段，解决管理的问题，尤其下游服务开发人员的跨部门协作问题**

### 注册中心核心功能

* 服务注册

  服务提供方将自身路由信息发布到注册中心，供服务消费方获取并用它来与提供方建立连接和发起远程调用。

  注册信息：

  * 路由信息：域名（或服务节点IP）、监听端口

  * 服务信息：序列化协议（Json、XML、pb）、路由规则（涉及CI/CD、灰度发布）、节点权重

* 服务发现

  服务消费方，通过访问注册中心，获取服务提供方节点的路由信息。

  交互方式：

  * 启动拉取：服务消费方启动后，从注册中心拉取提供方节点列表，建立连接，进行RPC调用。
  * 通知回调：接受注册中心变更通知，重新获取数据，更新节点列表。（电话模型、BP机模型）
  * 轮询拉取：服务消费方运行过程中定时拉取服务提供方节点列表，用来更新本地数据。

  > 通知事件带来奇异问题，由轮询拉取做兜底策略来解决。

* 健康检查

  确保已注册节点的健康度，能够及时准确剔除失效节点，保证服务发现的正确性。

  失效原因：部署重启、异常终止、服务假死

  解决方案：上报心跳、服务探测

  > **服务假死**
  >
  > 在服务提供方内部，一般通过一个独立的线程上报心跳到注册中心；当工作线程阻塞时，心跳上报仍然是正常的，此时服务提供方处于“假死”状态；“假死”一般通过探测才能发现。

* 变更通知

  当服务提供方节点发生变更时，注册中心应该能够第一时间把变更事件或变更后的数据推送到服务订阅方。

  > **订阅与通知**
  >
  > 注册中心为每个服务提供方建立订阅列表，当服务提供方节点变更时，通知所有订阅该服务的消费方节点。

![注册中心核心功能](Zookeeper\imgs\注册中心核心功能.png)



## 设计分析（设计者）

### 数据结构

有向无环图，KList邻接表

服务提供者`PA`的节点集合`PA-1`、`PA-2`、`PA-3`、……

服务消费者`CA`的节点集合`CA-1`、`CA-2`、`CA-3`、……

订阅关系：

> 集群维度、节点维度

### 健康检查

超时扫描
* map：map存储节点信息；心跳来了更新节点信息；**定时暴力枚举遍历**节点检测是否超时
* map+链表尾插：链表存储节点信息；心跳来了删除节点信息，并使用尾插法添加新节点信息。使用 map 优化提高定位速度。定时检测首节点是否超时。
* 动态分组：批量超时

服务节点上报心跳时，将失效时间对桶取余，放到指定桶里，把同一秒的节点放到同一个桶里；

游标每秒移动一次指向的桶，表示桶里的部分节点超时了；

节点每次有心跳上报，则动态移动到相应的桶中，来实现周期有效性。



``` java
class Solution {
    Map<Integer, HeatBeatInfo> nodes;
    
    // 找出超时节点
    List<Integer> findTimeOutNodes(long expireTime) {
        List<Integer> ls = new ArrayList<>();
        for (HeatBeatInfo info : nodes.values()) {
            if (info.expireTime < expireTime) list.add(info.nodeIP);
        }
        for (int nodeIP : ls) nodes.remove(nodeIP);
        return ls;
    }
    
    // 接收心跳
    void heatBeat(HeatBeatInfo info) {
        nodes.add(info.nodeIP, info);
    }
    
}

class HeatBeatInfo {
    long expireTime;
    int nodeIP;
}
```



### 变更通知

* 如何发送到指定节点
* 共识算法

Paxos协议、Raft协议、ZAB协议、gossip协议

> **gossip协议** 
>
> Epidemic Protocol （流行病协议），实际上它还有很多别名，比如：“流言算法”、“疫情传播算法”等。
>
> 它是一个通信协议，一种传播消息的方式，灵感来自于：瘟疫、社交网络等。
>
> 使用Gossip协议的有：Redis Cluster、Consul、Apache Cassandra等。



#### gossip协议

* 六度分离理论
* 周期性散播消息
* 随机选择N个节点散播
* 散播不重复不回传



**六度分隔理论**

你和任何一个陌生人之间所间隔的人不会超过六个，也就是说，最多通过六个人你就能够认识任何一个陌生人。

基本思想：一个节点想要分享一些信息给网络中的其他的一些节点。于是，它**周期性**的**随机**选择一些节点，并把信息传递给这些节点。这些收到信息的节点接下来会做同样的事情，即把这些信息传递给其他一些随机选择的节点。一般而言，信息会周期性的传递给N个目标节点，而不只是一个。这个N被称为**fanout**（这个单词的本意是扇出）。





## 本质（面试重点）

注册中心的短暂不可用是可能的，所以必须要有容错，比如服务消费者的本地缓存方式

注册中心要实现的功能：订阅和存储

### 存储系统关注点

* 服务可用性：多节点对等的对外提供服务
* 数据可靠性：数据冗余存储，确保不会因为单节点故障导致数据丢失。
* 一致性保障：各节点间数据同步，保证数据一致性

> 稳定性：可用+可靠
>
> 互联网强调整体稳定性，必须7X24小时工作。稳定性包括可用性、可靠性。要实现稳定性唯一手段就是冗余。冗余副本必须保障一致性。

### CAP理论

一个分布式系统不可能同时满足数据一致性、服务可用性、分区容错性这三个基本需求，最多只能同时满足其中的两项。

* 适用系统

  节点之间有连接，并且数据之间共享的分布式存储系统

  反例：memcached 

  分布式存储系统、分布式计算系统。

* 适用行为

  读写

  反例：Zookeeper 选主

* 何为P：Partition Tolerance

  在分布式系统中，除非是整个网络环境都发生了故障，否则在遇到任何网络分区故障的时候，仍然需要能够保证对外提供满足一致性和可用性的服务。

* 何为C：Consistency

  在分布式系统中，数据在多个副本之间是否能够保持一致的特性。

  也就是说，当一个系统在数据一致的状态下执行更新操作后，应该保证系统的数据仍然处于一致的状态。

  如果能够做到针对一个数据项的更新操作执行成功后，所有的用户都**可以读取到其最新的值**，那么这样的系统就被认为具有强一致性（或者严格的一致性）。

* 何为A：Availability

  系统提供的服务必须一直处于可用的状态。

  也就是说，对于用户的每一个操作请求总是能够在**有限的时间内返回合理结果**。

### AP/CP选择

选择哪种模型作为注册中心，需要从业务场景出发。

* 注册中心集群内网络分区

  牺牲一致性继续提供服务  VS  待恢复一致性状态后提供服务、

  服务消费：获取不同的节点列表好过无法获取节点

  服务提供：部分节点提供服务好过全部不可用

  > 症状：很多服务找不到下游，连接无法建立，大量请求报错。
  >
  > 不要过度依赖注册中心，消费方本地要有缓存

* CP or AP

  AP模型更适合作注册中心

* CP 可以作为注册中心吗？

  可以。ZK + 本地缓存

## 选型对比

注册中心选型：考虑CAP，结合实际场景，多维度综合评估。

* 数据模型
* 数据一致性
* 健康检查
* 性能与容量
* 稳定性
* 易用性
* 集群扩展性
* 成熟度
* 社区活跃程度





Zookeeper 的数据一致性是顺序一致性；同时CP模型表达的也不是数据的强一致性。



Zookeeper 的Follower节点作为代理，会将客户端的数据写入请求转发给Leader；

Zookeeper半数通过即提交的写入机制保证的是最终一致性，不会造成数据丢失。
